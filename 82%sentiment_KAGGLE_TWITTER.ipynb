{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import STOPWORDS, WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Vinayak Sidharth\\Documents\\twitter//train.csv', encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target          id                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['flag'],axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = np.array(df['user'].unique() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = np.array(df['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_val = np.array(df['target'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttarg(i,df):\n",
    "    print('{}_is the target\\n'.format(np.array(df['target'].values)[i]))\n",
    "    print(np.array(df['text'].values)[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df.sample(frac=1, random_state = 43)\n",
    "df_1['text'] = df_1['text'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_is the target\n",
      "\n",
      "so they WON YEAH!! a little late cause i kept rewinding the dang thing \n"
     ]
    }
   ],
   "source": [
    "ttarg(10,df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poss(val):\n",
    "    if val == 4:\n",
    "        res = 1\n",
    "    else :\n",
    "        res = 0\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['target'] = df_1['target'].apply(lambda x : poss(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_0 = np.array(df_1.loc[df_1['target']==0]['text'].values)\n",
    "text_1 = np.array(df_1.loc[df_1['target']==1]['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = df_1.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_1.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"@speakforme I know. We should go asap. like when we get back home I wanna buy jeans, too. But I'm too fat for jeans. \",\n",
       "       '@Lisa_Nova we had it but we lost it  very sad 4 us cause we loved it',\n",
       "       \"I would've wifed @KiyastarW ... if only she would have me! \", ...,\n",
       "       'locked out of my outlook account for the 3rd time in 3 days ',\n",
       "       \"Ugh. Slept 'til now. My cold hath blossomed during the night. \",\n",
       "       '@sourapplemedia is that coffee house at City Center?  I miss the Italian Ice shop next door '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_is the target\n",
      "\n",
      "@winniedepoohi it was good .. but not better than the time we had \n"
     ]
    }
   ],
   "source": [
    "ttarg(222,df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS.add('ibm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_txt(text):\n",
    "    final = []\n",
    "    final2 = []\n",
    "    for num,i in enumerate(text):\n",
    "        lower = []\n",
    "        word_arr = i.split()\n",
    "        for j in word_arr:\n",
    "            lower.append(j.lower())\n",
    "        \n",
    "        spell = SpellChecker()\n",
    "        misspelled = spell.unknown(lower)\n",
    "        \n",
    "        for word in misspelled:\n",
    "            lower.remove(word)\n",
    "            lower.append(spell.correction(word))\n",
    "        final.append(lower)\n",
    "        num = num + 1\n",
    "\n",
    "    \n",
    "            \n",
    "    for j in final:\n",
    "        final2.append(list(filter(lambda x: x[0]!= '@', j)))\n",
    "        \n",
    "        \n",
    "    return final, final2\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_notxt(text):\n",
    "    final = []\n",
    "    final2 = []\n",
    "    for num,i in enumerate(text):\n",
    "        lower = []\n",
    "        word_arr = i.split()\n",
    "        for j in word_arr:\n",
    "            lower.append(j.lower())\n",
    "        final.append(lower)\n",
    "            \n",
    "        num = num + 1\n",
    "        if num %100000 ==0:\n",
    "            print('{}/{}'.format(num,len(text)))\n",
    "            \n",
    "    for j in final:\n",
    "        final2.append(list(filter(lambda x: x[0]!= '@', j)))\n",
    "        \n",
    "        \n",
    "    return final, final2\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_array(popo):\n",
    "    coom = []\n",
    "    for i in popo:\n",
    "        for j in i:\n",
    "            coom.append(j)\n",
    "    print('task 2 over')\n",
    "    return coom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cloud(stop, arr):\n",
    "    das = ' '\n",
    "    sten = das.join(arr)\n",
    "    \n",
    "    cloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='salmon',\n",
    "                          colormap='Pastel1', collocations=False, stopwords = stop)\n",
    "    cloud.generate(sten)\n",
    "    \n",
    "    print('GENERATED')\n",
    "    \n",
    "    plt.figure(figsize=(17,8))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(cloud)\n",
    "\n",
    "    return sten\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def master_plot(array):\n",
    "    trash,wordz = correct_notxt(array)\n",
    "    real_wordz = combine_array(wordz)\n",
    "    plot_cloud(STOPWORDS,real_wordz )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(y1,y2):\n",
    "    new = []\n",
    "    for j in y1:\n",
    "        if j >=0.5:\n",
    "            new.append(1)\n",
    "        else:\n",
    "            new.append(0)\n",
    "    call = 0\n",
    "    for i,val in enumerate(ytest):\n",
    "        if val==new[i]:\n",
    "            call = call+1\n",
    "            \n",
    "    return call/len(y1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "texx_1 = text_1[:20]\n",
    "texx_0 = text_0[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_plot(texx_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_plot(texx_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "u,i = correct_notxt(text_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonspell= i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "master_plot(text_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "master_plot(text_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/1600000\n",
      "200000/1600000\n",
      "300000/1600000\n",
      "400000/1600000\n",
      "500000/1600000\n",
      "600000/1600000\n",
      "700000/1600000\n",
      "800000/1600000\n",
      "900000/1600000\n",
      "1000000/1600000\n",
      "1100000/1600000\n",
      "1200000/1600000\n",
      "1300000/1600000\n",
      "1400000/1600000\n",
      "1500000/1600000\n",
      "1600000/1600000\n"
     ]
    }
   ],
   "source": [
    "noval , X_2 = correct_notxt(X_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = []\n",
    "for i,val in enumerate(X_2):\n",
    "    if len(val) == 0:\n",
    "        cc.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmove = np.array(X_1)[cc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = np.delete(X_2, cc)\n",
    "y = np.delete(y, cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1597258"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1597258"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_size = 100000\n",
    "X_test = X_2[-tst_size:]\n",
    "y_test = y[-tst_size:]\n",
    "X_train = X_2[:len(X_2)-tst_size]\n",
    "y_train = y[:len(y)-tst_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "inn = tf.keras.preprocessing.text.Tokenizer(num_words = 60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "inn.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = inn.word_index.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = inn.texts_to_sequences(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = inn.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_sequences = tf.keras.preprocessing.sequence.pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pad_tr = pad_sequences(X_train , maxlen = 57)\n",
    "X_pad_ts = pad_sequences(X_test , maxlen = 57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1497258, 57)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pad_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr=[]\n",
    "ts=[]\n",
    "for i,val in enumerate(X_train):\n",
    "    if len(val)==0:\n",
    "        tr.append(i)\n",
    "for j,xa in enumerate(X_test):\n",
    "    if len(xa)==0:\n",
    "        ts.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pad_tr = np.array(X_pad_tr)\n",
    "X_pad_ts = np.array(X_pad_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pad_tr= np.delete(X_pad_tr, tr,0)\n",
    "X_pad_ts= np.delete(X_pad_ts, ts,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.delete(y_train, tr)\n",
    "y_test = np.delete(y_test, ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train = (1493300, 57), y_train = (1493300,) , x_test = (99735, 57), y_test = (99735,)\n"
     ]
    }
   ],
   "source": [
    "print('x train = {}, y_train = {} , x_test = {}, y_test = {}'.format(X_pad_tr.shape, y_train.shape,X_pad_ts.shape, y_test.shape ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('xtrain.pickle','w+b') as f:\n",
    "    pickle.dump(X_pad_tr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('ytrain.pickle','w+b') as f:\n",
    "    pickle.dump(y_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('xtest.pickle','w+b') as f:\n",
    "    pickle.dump(X_pad_ts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('ytest.pickle','w+b') as f:\n",
    "    pickle.dump(y_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('xtrain.pickle','r+b') as f:\n",
    "    xtrain= pickle.load( f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('ytrain.pickle','r+b') as f:\n",
    "    ytrain= pickle.load( f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('xtest.pickle','r+b') as f:\n",
    "    xtest= pickle.load( f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('ytest.pickle','r+b') as f:\n",
    "    ytest= pickle.load( f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99735,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99735, 57)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1493300, 57)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1493300,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "valsize = 300000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val = xtrain[:valsize]\n",
    "#yval = ytrain[:valsize]\n",
    "#xtrain = xtrain[valsize:]\n",
    "#ytrain = ytrain[valsize :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(60000, 32))\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)))\n",
    "model.add(tf.keras.layers.Dense(64, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', metrics=['accuracy'], loss='binary_crossentropy' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1075176 samples, validate on 418124 samples\n",
      "Epoch 1/5\n",
      "1075176/1075176 [==============================] - 2148s 2ms/sample - loss: 0.4201 - accuracy: 0.8063 - val_loss: 0.3915 - val_accuracy: 0.8230\n",
      "Epoch 2/5\n",
      "1075176/1075176 [==============================] - 2251s 2ms/sample - loss: 0.3625 - accuracy: 0.8390 - val_loss: 0.3841 - val_accuracy: 0.8270\n",
      "Epoch 3/5\n",
      "1075176/1075176 [==============================] - 2345s 2ms/sample - loss: 0.3292 - accuracy: 0.8573 - val_loss: 0.3876 - val_accuracy: 0.8264\n",
      "Epoch 4/5\n",
      "1075176/1075176 [==============================] - 4206s 4ms/sample - loss: 0.2992 - accuracy: 0.8730 - val_loss: 0.4026 - val_accuracy: 0.8208\n",
      "Epoch 5/5\n",
      "1075176/1075176 [==============================] - 3665s 3ms/sample - loss: 0.2711 - accuracy: 0.8874 - val_loss: 0.4227 - val_accuracy: 0.8155\n"
     ]
    }
   ],
   "source": [
    "fitted = model.fit(xtrain, ytrain,  validation_split = 0.28, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\vinayak sidharth\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Vinayak Sidharth\\Documents\\TWITTER_HAPPINESS.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(r'C:\\Users\\Vinayak Sidharth\\Documents\\TWITTER_HAPPINESS.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JUST STOP ON 2 EPCOH IT IS THE BEST ONE DO IT LAST ONE YOU DO\n"
     ]
    }
   ],
   "source": [
    "print('JUST STOP ON 2 EPCOH IT IS THE BEST ONE DO IT LAST ONE YOU DO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8126234521481928"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(pred,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tf.keras.models.Sequential()\n",
    "model1.add(tf.keras.layers.Embedding(60000, 32))\n",
    "model1.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences = True)))\n",
    "model1.add(tf.keras.layers.Reshape((57,64,1)))\n",
    "model1.add(tf.keras.layers.Conv2D(32, kernel_size = (3,3)))\n",
    "model1.add(tf.keras.layers.MaxPooling2D(4))\n",
    "model1.add(tf.keras.layers.Conv2D(32, kernel_size = (4,4)))\n",
    "model1.add(tf.keras.layers.MaxPooling2D(3))\n",
    "model1.add(tf.keras.layers.Flatten() )\n",
    "model1.add(tf.keras.layers.Dense(100, activation = 'relu'))\n",
    "model1.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile( optimizer = 'adam', loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1194640 samples, validate on 298660 samples\n",
      "Epoch 1/3\n",
      "1194640/1194640 [==============================] - 4318s 4ms/sample - loss: 0.4224 - accuracy: 0.8053 - val_loss: 0.3952 - val_accuracy: 0.8207\n",
      "Epoch 2/3\n",
      "1194640/1194640 [==============================] - 4322s 4ms/sample - loss: 0.3685 - accuracy: 0.8363 - val_loss: 0.3881 - val_accuracy: 0.8256\n",
      "Epoch 3/3\n",
      "1194640/1194640 [==============================] - 3441s 3ms/sample - loss: 0.3400 - accuracy: 0.8518 - val_loss: 0.3917 - val_accuracy: 0.8257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28a84cc5508>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(xtrain,ytrain,validation_split=0.2,epochs = 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'C:\\Users\\Vinayak Sidharth\\Documents\\TWITTER_HAPPINESS.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model size is almost 25 mb and takes about 1 hour per epoch but we can see the model is starting to overfit\n",
    "#SO WITH MORE DATA I AND MORE EPPOCHS I CAN SEE THIS MODEL WORKING WAAAY BETTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = tf.keras.layers.Conv2D(32, kernel_size = (3,3)) (ii)\n",
    "t = tf.keras.layers.MaxPooling2D(2)(o)\n",
    "o2 = tf.keras.layers.Conv2D(32, kernel_size = (3,3))(o)\n",
    "t2 = tf.keras.layers.MaxPooling2D(2)(o2)\n",
    "r = tf.keras.layers.Reshape((12,-1))(t2)\n",
    "l = tf.keras.layers.LSTM(200)(r)\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelp = tf.keras.models.Sequential()\n",
    "modelp.add(tf.keras.layers.Conv2D(32, kernel_size = (3,3)))\n",
    "modelp.add(tf.keras.layers.MaxPooling2D(4))\n",
    "modelp.add(tf.keras.layers.Conv2D(32, kernel_size = (4,4)))\n",
    "modelp.add(tf.keras.layers.MaxPooling2D(3))\n",
    "modelp.add(tf.keras.layers.Flatten())\n",
    "modelp.compile(optimizer = 'adam', metrics=['accuracy'], loss='binary_crossentropy' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = modelp.predict(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 384)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = tf.random.normal((2,57,64,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "oon = tf.keras.layers.Conv2D(32, kernel_size = (4,4))(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss11 = tf.random.normal((2,12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,2,3,4,1,5,33],[5,5,3,2,2,1,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "po = tf.keras.layers.Embedding(34,3)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(3, return_sequences = True))(po)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "nss =  tf.keras.layers.LSTM(12)(ss11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "popo = tf.keras.layers.Reshape((7,6,1))(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = tf.keras.layers.Conv2D(32, kernel_size = (2,2))(popo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx = tf.keras.layers.MaxPooling2D(2)(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crz = tf.kears.LSTM(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls1 = tf.keras.layers.LSTM(12, return_sequences = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls2 = tf.keras.layers.LSTM(12, go_backwards = True,return_sequences = True ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss1 = tf.keras.layers.Bidirectional(ls1,backward_layer = ls2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "forward_layer = tf.keras.layers.LSTM(10, return_sequences=True)\n",
    "backward_layer = tf.keras.layers.LSTM(10, activation='relu', return_sequences=True,\n",
    "                       go_backwards=True)\n",
    "model.add(tf.keras.layers.Bidirectional(forward_layer, backward_layer=backward_layer,\n",
    "                        input_shape=(7, 3) ))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
